---
title: "Pinera Speeches"
author: "Andrés Ponce"
output: html_notebook
---

```{r include=FALSE}
#install.packages("FactoMineR")
library(FactoMineR)
library(readtext)
library(quanteda)
library(dplyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(RColorBrewer)
library(haven)
library(readxl)
library(tidyverse)
library(parallel)
library(topicmodels)
library(ldatuning)
library(stm)
library(gridExtra)
```


```{r include=FALSE}
corpus <- corpus(sample_disc, text_field = "discursos") #creating corpus
pin<-summary(corpus, 582) %>% arrange(desc(fecha)) #summary of speeches + sorting date in desc order

# subsetting corpus by years
corpus2020<- corpus %>% corpus_subset(fecha >= as.Date("2020-01-01")) %>% summary()
corpus2019<- corpus %>% corpus_subset(fecha >= as.Date("2019-01-01") & fecha <= as.Date("2019-12-31")) %>% summary(271)
corpus2018<- corpus %>% corpus_subset(fecha >= as.Date("2018-01-01")& fecha <= as.Date("2018-12-31")) %>% summary(302)

#include a variable month
corpus2019$mes<- months(corpus2019$fecha) 
corpus2019$mes<-factor(corpus2019$mes,levels=month.name)

corpus2018$mes<- months(corpus2018$fecha)
corpus2018$mes<-factor(corpus2018$mes,levels=month.name)

#creating plots
pin_count1<- corpus2020 %>% ggplot(aes(x= mes,y= Tokens))+
  geom_bar(color="blue", stat="identity")+
  theme_bw()+
  labs(x = "Month", y = "Average token count by speeches") +
  scale_x_date(date_labels = "%b %Y", date_breaks = "1 months")

      #arrange dates in order to plot
pin_count2<-corpus2019 %>% ggplot(aes(x=mes, y=Tokens))+
  stat_summary(fun.y=sum,geom="bar",fill="#808080",colour="black")+
  theme_bw()+
  labs(x = "Months of 2019", y = "Token Count",
       title = "Distribution of Tokens for Oficial Speeches of President Pinera",
       subtitle = "montly distribution from March 2018 to December 2019") +
  scale_y_continuous(limits = c(0, 100000))
  
                                  
pin_count3<-corpus2018 %>% ggplot(aes(x= mes, y=Tokens))+
  theme_bw()+
  stat_summary(fun.y=sum,geom="bar",fill="#808080",colour="black")+
  labs(x = "Months of 2018", y = "Token Count")+
  scale_y_continuous(limits = c(0, 100000))

```

```{r}
gridExtra::grid.arrange(pin_count2, pin_count3, nrow = 2)
```

```{r}
# frecquency of speeches by month-year
  mes2018<-count(corpus2018, mes) 
  mes2018
  mean(mes2018$n)
  mes2019<-count(corpus2019, mes)
  mes2019
  mean(mes2019$n)
```



```{r}
dfm_pin_2018 <- corpus %>% corpus_subset(fecha >= as.Date("2019-01-01") & fecha <= as.Date("2019-12-31")) %>% dfm(what = "word", remove=c(stopwords("es"), "chile", "Chile", "va", "país"), #Tokenize democratic speeches
              remove_punct = TRUE,
              remove_symbols = TRUE,
              remove_numbers = TRUE,
              remove_twitter = TRUE,
              remove_url = TRUE,
               remove_hyphens = TRUE,
              verbose = TRUE, 
              stem=T,
              include_docvars = TRUE)  %>%  dfm_trim(min_termfreq = 10)

dfm_pin_2019<- corpus %>% corpus_subset(fecha >= as.Date("2018-01-01")& fecha <= as.Date("2018-12-31")) %>% dfm(what = "word", remove=c(stopwords("es"),"chile", "Chile", "va", "país"), #Tokenize democratic speeches
              remove_punct = TRUE,
              remove_symbols = TRUE,
              remove_numbers = TRUE,
              remove_twitter = TRUE,
              remove_url = TRUE,
               remove_hyphens = TRUE,
              verbose = TRUE, 
              stem=T,
              include_docvars = TRUE)  %>%  dfm_trim(min_termfreq = 10)


#Frecquency
features_dfm_pin_2018 <- textstat_frequency(dfm_pin_2018, n = 30)
features_dfm_pin_2019 <- textstat_frequency(dfm_pin_2019, n = 30)

# Sort by reverse frequency order
features_dfm_pin_2018$feature <- with(features_dfm_pin_2018, reorder(feature, -frequency))
features_dfm_pin_2019$feature <- with(features_dfm_pin_2019, reorder(feature, -frequency))

frec_2018<- ggplot(features_dfm_pin_2018, aes(x = feature, y = frequency)) +
    geom_point() + 
  labs(x = "Frequency", y = "Words")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))

frec_2019<- ggplot(features_dfm_pin_2019, aes(x = feature, y = frequency)) +
    geom_point() + 
  labs(x = "Frequency", y = "Words")+
    theme(axis.text.x = element_text(angle = 45, hjust = 1))
```


```{r}
gridExtra::grid.arrange(frec_2018, frec_2019, nrow = 2)
```



```{r}
textplot_wordcloud(dfm_pin_2018, min_count=100, random_order = F, comparison=F, rotation=.25, color= RColorBrewer::brewer.pal(5,"Dark2"))
```





```{r}
word.frequencies <- textstat_frequency(dfm_pin) # more elaborate frequencies
head(word.frequencies, 50)
```

```{r}
collocations <- textstat_collocations(corpus, min_count = 10)
arrange(collocations, desc(count))
```



```{r}

n.topics <- 8
dfm2topicmodels <- convert(dfm_pin, to = "topicmodels")
lda.model <- LDA(dfm2topicmodels, n.topics)
as.data.frame(terms(lda.model, 10))

no_cores <- detectCores() - 1
ldatuning.metrics <- FindTopicsNumber(dfm2topicmodels, topics = seq(from = 2, to = 100, by = 10), metrics = c("Griffiths2004", "CaoJuan2009", "Arun2010", "Deveaud2014"), method = "Gibbs", control = list(seed = 77), mc.cores = no_cores, verbose = TRUE
)

FindTopicsNumber_plot(ldatuning.metrics)

```
```{r}
dfm2stm <- convert(dfm_pin, to = "stm")
mein.stm.idealK <- searchK(dfm2stm$documents, dfm2stm$vocab, K = seq(4, 60, by = 2))

plot(mein.stm.idealK)
```
```{r}
modell.stm1 <- stm(dfm2stm$documents, dfm2stm$vocab, prevalence = ~fecha, K = 7, data = dfm2stm$meta, init.type = "Spectral")
modell.stm2 <- stm(dfm2stm$documents, dfm2stm$vocab,prevalence =~ fecha, K = 15, data = dfm2stm$meta, init.type = "Spectral")
modell.stm3 <- stm(dfm2stm$documents, dfm2stm$vocab, prevalence =~ fecha,K = 50, data = dfm2stm$meta, init.type = "Spectral")
as.data.frame(t(labelTopics(modell.stm1, n = 10)$prob))

```


```{r}
M7ExSem<-as.data.frame(cbind(c(1:7),exclusivity(modell.stm1), semanticCoherence(model=modell.stm1, dfm2stm$documents), "Mod7"))
M12ExSem<-as.data.frame(cbind(c(1:15),exclusivity(modell.stm2), semanticCoherence(model=modell.stm2, dfm2stm$documents), "Mod12"))
M20ExSem<-as.data.frame(cbind(c(1:50),exclusivity(modell.stm2), semanticCoherence(model=modell.stm3, dfm2stm$documents), "Mod40"))

ModsExSem<-rbind(M7ExSem, M12ExSem, M20ExSem)
colnames(ModsExSem)<-c("K","Exclusivity", "SemanticCoherence", "Model")

ModsExSem$Exclusivity<-as.numeric(as.character(ModsExSem$Exclusivity))
ModsExSem$SemanticCoherence<-as.numeric(as.character(ModsExSem$SemanticCoherence))

options(repr.plot.width=7, repr.plot.height=7, repr.plot.res=100)

plotexcoer<-ggplot(ModsExSem, aes(SemanticCoherence, Exclusivity, color = Model))+geom_point(size = 2, alpha = 0.7) + 
geom_text(aes(label=K), nudge_x=.05, nudge_y=.05)+
  labs(x = "Semantic coherence",
       y = "Exclusivity",
       title = "Comparing exclusivity and semantic coherence")

plotexcoer
```

```{r}
plot(modell.stm3, type = "summary", text.cex = 0.9, main = "Topic shares on the corpus as a whole", xlab = "estimated share of topics")
```

```{r}
plot(modell.stm2, type = "labels", topics = c(23,30, 36,11), main = "Topic terms")
```

```{r}
as.data.frame(t(labelTopics(modell.stm1, n = 10)$prob))
```
